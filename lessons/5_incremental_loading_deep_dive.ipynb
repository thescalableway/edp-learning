{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35609359",
   "metadata": {},
   "source": [
    "# Incremental loading: deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64201040",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "\n",
    "In this lesson, we will take a deep dive into how incremental loading works in `dlt`, and how you can customize it to fit your needs.\n",
    "\n",
    "We will also learn:\n",
    "- how to perform backfills\n",
    "- how to handle late arriving data\n",
    "- how to debug common incremental loading issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eea93d3",
   "metadata": {},
   "source": [
    "## 2. How incremental loading works in `dlt`\n",
    "\n",
    "There are two main components that work together to enable incremental loading in `dlt`:\n",
    "\n",
    "- Cursor configuration\n",
    "- Pipeline state\n",
    "\n",
    "In short, we can configure a cursor to let `dlt` know how to identify new or updated rows in the source data. `dlt` will then store the last seen cursor value in the pipeline state, and use it to filter the source data on subsequent runs.\n",
    "\n",
    "Notably, the filtering is performed **after** the data is extracted from the source and any [mapping funcions](https://dlthub.com/docs/dlt-ecosystem/transformations/add-map), but **before** it is normalized and loaded into the destination.\n",
    "\n",
    "### Cursor configuration\n",
    "\n",
    "The cursor configuration consists of the following components:\n",
    "\n",
    "- Cursor column\n",
    "- Cursor initial value\n",
    "- Cursor end value (optional)\n",
    "\n",
    "The latter two, combined with pipeline state, are used by `dlt` to determine the current cursor value at the start of each pipeline run.\n",
    "\n",
    "For more information on how pipeline state is used in incremental loading, see the [Pipeline state](#pipeline-state) section below.\n",
    "\n",
    "#### Cursor column\n",
    "\n",
    "This is the column in the source data that `dlt` uses to determine which rows are new or updated since the last load. It's typically a timestamp or an incrementing integer.\n",
    "\n",
    "#### Cursor value\n",
    "\n",
    "This is the value of the cursor column from the last successful load. `dlt` uses this value to filter the source data. We can manually specify the initial and end values for specific purposes.\n",
    "\n",
    "#### Cursor initial value\n",
    "\n",
    "This is the value that `dlt` uses for the cursor value on the first run of the pipeline. It is specified in the `dlt` configuration file (`config.toml`).\n",
    "\n",
    "#### Cursor end value\n",
    "\n",
    "This is used by `dlt` for backfills. Specifing this value tells `dlt` to **not** update the cursor value after the run, allowing you to re-extract data up to this value in subsequent runs.\n",
    "\n",
    "### Pipeline state\n",
    "\n",
    "This is a persistent storage that `dlt` uses to store\n",
    "the cursor value and other metadata about the pipeline runs. It allows `dlt` to remember the state of the pipeline between runs.\n",
    "\n",
    "Below is a diagram showcasing how pipeline state is used during a pipeline run:\n",
    "\n",
    "![dlt incremental loads - pipeline state](../assets/dlt_incremental_loads_pipeline_state.png)\n",
    "\n",
    "Notably, on the first execution, the pipeline will use the specified `cursor_initial_value` to filter the data:\n",
    "\n",
    "![dlt incremental loads - pipeline state - first run](../assets/dlt_incremental_loads_pipeline_state__first_run.png)\n",
    "\n",
    "\n",
    "### Cursor value types & timezones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70ee4fe",
   "metadata": {},
   "source": [
    "## 3. Backfilling data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a2834",
   "metadata": {},
   "source": [
    "## 4. Handling late arriving data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896150f4",
   "metadata": {},
   "source": [
    "## 5. Debugging incremental loading issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5972dbf8",
   "metadata": {},
   "source": [
    "### 5.1 Incorrect cursor column name\n",
    "\n",
    "#### Specifying normalized name\n",
    "\n",
    "When\n",
    "\n",
    "Remember that incremental filtering is applied **after** the data is extracted and any mapping functions are applied, but **before** normalization and loading. Due to this, we need to use the non-normalized column name when specifying the cursor column:\n",
    "\n",
    "Resource:\n",
    "\n",
    "```json\n",
    "{\"MyColumn\": \"value\"}\n",
    "```\n",
    "\n",
    "Incorrect incremental configuration:\n",
    "```python\n",
    "dlt.sources.incremental(\"my_column\")\n",
    "```\n",
    "\n",
    "Correct incremental configuration:\n",
    "```python\n",
    "dlt.sources.incremental(\"MyColumn\")\n",
    "```\n",
    "\n",
    "\n",
    "#### Not escaping special characters\n",
    "\n",
    "A common issue is when the resource retrieves data in the following format:\n",
    "\n",
    "```json\n",
    "{\"My Column\": \"value\"}\n",
    "```\n",
    "\n",
    "And then we try to specify the cursor column as:\n",
    "\n",
    "```python\n",
    "dlt.sources.incremental(\"My Column\")\n",
    "```\n",
    "\n",
    "However, internally, `dlt` uses JSONPath to select the cursor value using our specified column name as part of the path. So, in this case, we need to escape the special characters (space) in the column name by wrapping it in `['...']`:\n",
    "\n",
    "```python\n",
    "dlt.sources.incremental(\"['My Column']\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c583a92",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
